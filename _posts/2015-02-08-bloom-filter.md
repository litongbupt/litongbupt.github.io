---
layout: post
title: "海量数据处理之二：Bloom Filter"
description: "Bloom Filter是一种空间效率很高的随机数据结构，它利用位数组很简洁地表示一个集合，并能判断一个元素是否属于这个集合。"
category: big-data-base 
tags: [bloom filter,布隆过滤器]
---
{% include JB/setup %}
##【什么是Bloom Filter】
Bloom Filter是一种空间效率很高的随机数据结构，它利用位数组很简洁地表示一个集合，并能判断一个元素是否属于这个集合。Bloom Filter的这种高效是有一定代价的：在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合（false positive）。因此，Bloom Filter不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，Bloom Filter通过极少的错误换取了存储空间的极大节省。 这里有一篇关于[Bloom Filter](http://www.xiangguo.li/big-data-base/2015/02/07/bloom-filter/)的详细介绍，不太懂的博友可以看看。

##【适用范围】
可以用来实现数据字典，进行数据的判重，或者集合求交集
 
##【基本原理及要点】
对于原理来说很简单，位数组+k个独立hash函数。将hash函数对应的值的位数组置1，查找时如果发现所有hash函数对应位都是1说明存在，很明显这个过程并不保证查找的结果是100%正确的。同时也不支持删除一个已经插入的关键字，因为该关键字对应的位会牵动到其他的关键字。所以一个简单的改进就是 counting Bloom filter，用一个counter数组代替位数组，就可以支持删除了。 

还有一个比较重要的问题，如何根据输入元素个数n，确定位数组m的大小及hash函数个数。当hash函数个数   
 
    k=(ln2)*(m/n)
    
时错误率最小。在错误率不大于E的情况 下，m至少要等于

    n*lg(1/E)
    
才能表示任意n个元素的集合。但m还应该更大些，因为还要保证bit数组里至少一半为0，则应该

    m>=nlg(1/E)*lge 

大概就是nlg(1/E)1.44倍(lg表示以2为底的对数)。 

举个例子我们假设错误率为0.01，则此时m应大概是n的13倍。这样k大概是8个。 

注意这里m与n的单位不同，m是bit为单位，而n则是以元素个数为单位(准确的说是不同元素的个数)。通常单个元素的长度都是有很多bit的。所以使用bloom filter内存上通常都是节省的。 
 
##【扩展】 
Bloom filter将集合中的元素映射到位数组中，用k（k为哈希函数个数）个映射位是否全1表示元素在不在这个集合中。Counting bloom filter（CBF）将位数组中的每一位扩展为一个counter，从而支持了元素的删除操作。Spectral Bloom Filter（SBF）将其与集合元素的出现次数关联。SBF采用counter中的最小值来近似表示元素的出现频率。 
 
##【问题实例】
给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢？ 

根据这个问题我们来计算下内存的占用，4G=2^32大概是40亿*8大概是340亿，n=50亿，如果按出错率0.01算需要的大概是650亿个bit。 现在可用的是340亿，相差并不多，这样可能会使出错率上升些。另外如果这些urlip是一一对应的，就可以转换成ip，则大大简单了。见下一节hash问题。

转自码农：<http://blog.redfox66.com/post/2010/09/24/mass-data-topic-2-bloom-filter.aspx>
